{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMDxLD/xS8/SpvXrjOnGK0q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuskanSinhaPi/Intern/blob/main/Copy_of_STHSL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf STHSL"
      ],
      "metadata": {
        "id": "t2hLsOfbR9s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHlYLHhl4v1v",
        "outputId": "3a562e2e-f5c3-429c-f33c-709a01c2c8cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'STHSL'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (92/92), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 101 (delta 41), reused 82 (delta 38), pack-reused 9\u001b[K\n",
            "Receiving objects: 100% (101/101), 7.07 MiB | 12.72 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MuskanSinhaPi/STHSL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd STHSL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJhZLBLj5FkI",
        "outputId": "eece8df9-3bea-4a1c-f1b6-3c3b881239f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/STHSL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preprocessing for SF Crime Dataset"
      ],
      "metadata": {
        "id": "yzwkQRRzMuzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load the dataset (adjust the path to your dataset)\n",
        "sf_crime = pd.read_csv('/content/STHSL/Datasets/SF_crime/SFCrime.csv')\n",
        "\n",
        "sf_crime = sf_crime[['Category', 'Descript', 'DayOfWeek', 'Date', 'Time', 'PdDistrict','Resolution', 'Address', 'X','Y']]\n",
        "\n",
        "#Data Cleaning\n",
        "# Drop rows with any missing values\n",
        "sf_crime.dropna(inplace=True)\n",
        "# Convert 'Date' and 'Time' columns to datetime because we can only use .dt accessor with datetimelike values\n",
        "sf_crime['datetime'] = pd.to_datetime(sf_crime['Date'] + ' ' + sf_crime['Time'])\n",
        "\n",
        "# Extract relevant features\n",
        "sf_crime['year'] = sf_crime['datetime'].dt.year\n",
        "sf_crime['hour'] = sf_crime['datetime'].dt.hour\n",
        "sf_crime['month'] = sf_crime['datetime'].dt.month\n",
        "sf_crime['day_of_week'] = sf_crime['datetime'].dt.dayofweek\n",
        "sf_crime['day'] = pd.to_datetime(sf_crime['datetime']).dt.day\n",
        "sf_crime['minute'] = pd.to_datetime(sf_crime['datetime']).dt.minute\n",
        "# Filter data for years before 2018 for training and use 2018 for testing\n",
        "train_df = sf_crime[sf_crime['year'] < 2018]\n",
        "test_df = sf_crime[sf_crime['year'] == 2018]\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode 'Category' (target variable)\n",
        "train_df['Category'] = label_encoder.fit_transform(train_df['Category'])\n",
        "test_df['Category'] = label_encoder.transform(test_df['Category'])\n",
        "\n",
        "features = ['PdDistrict','hour','day','minute','day_of_week', 'month', 'X', 'Y']\n",
        "X_train = train_df[features]\n",
        "y_train = train_df['Category']\n",
        "X_test = test_df[features]\n",
        "y_test = test_df['Category']\n",
        "\n",
        "# One-hot encode the 'PdDistrict' feature\n",
        "X_train = pd.get_dummies(X_train, columns=['PdDistrict'])\n",
        "X_test = pd.get_dummies(X_test, columns=['PdDistrict'])\n",
        "\n",
        "# Ensure the columns match between train and test sets\n",
        "X_train, X_test = X_train.align(X_test, join='left', axis=1, fill_value=0)\n",
        "\n",
        "# Combine train and test data to ensure all unique regions are captured\n",
        "all_data = pd.concat([train_df, test_df])\n",
        "unique_regions = all_data[['X', 'Y']].drop_duplicates().reset_index(drop=True)\n",
        "region_map = {tuple(region): idx for idx, region in unique_regions.iterrows()}\n",
        "\n",
        "# Function to create a region ID\n",
        "def get_region_id(row):\n",
        "    # Handle cases where (X, Y) pair is not found in region_map\n",
        "    return region_map.get((row['X'], row['Y']), -1)  # Assign -1 for unknown regions\n",
        "\n",
        "train_df['region'] = train_df.apply(get_region_id, axis=1)\n",
        "test_df['region'] = test_df.apply(get_region_id, axis=1)\n",
        "\n",
        "# Pivot table to reshape data\n",
        "train_pivot = train_df.pivot_table(index='region', columns='datetime', values=features, aggfunc='mean')\n",
        "test_pivot = test_df.pivot_table(index='region', columns='datetime', values=features, aggfunc='mean')\n",
        "\n",
        "# Fill NaNs with 0\n",
        "train_pivot = train_pivot.fillna(0)\n",
        "test_pivot = test_pivot.fillna(0)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "train_array = train_pivot.to_numpy()\n",
        "test_array = test_pivot.to_numpy()\n",
        "\n",
        "# Assume args.row and args.col are predefined based on the unique regions\n",
        "args.row = len(unique_regions)\n",
        "args.col = 1  # Adjust based on your dataset's structure\n",
        "args.offNum = len(features)\n",
        "\n",
        "# Reshape the arrays\n",
        "train_array = train_array.reshape((args.row, args.col, -1, args.offNum))\n",
        "test_array = test_array.reshape((args.row, args.col, -1, args.offNum))\n",
        "\n",
        "# Save the arrays as .pkl files\n",
        "with open('/content/STHSL/Datasets/SF_crime/trn.pkl', 'wb') as f:\n",
        "    pickle.dump(train_array, f)\n",
        "with open('/content/STHSL/Datasets/SF_crime/val.pkl', 'wb') as f:\n",
        "    pickle.dump(test_array, f)\n",
        "with open('/content/STHSL/Datasets/SF_crime/tst.pkl', 'wb') as f:\n",
        "    pickle.dump(test_array, f)\n",
        "\n",
        "# Reshape the arrays as required by the model (example: [region, days, features])\n",
        "# This step will depend on how your model expects the data to be shaped"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "mA1YePeBMuCN",
        "outputId": "a7bb2d08-b54e-4c32-8481-a98ca85523de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot set a DataFrame with multiple columns to the single column region",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-618950e16ffa>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'region'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_region_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'region'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_region_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Pivot table to reshape data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3938\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3939\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3940\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3941\u001b[0m         elif (\n\u001b[1;32m   3942\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item_frame_value\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4094\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   4095\u001b[0m                 \u001b[0;34m\"Cannot set a DataFrame with multiple columns to the single \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4096\u001b[0m                 \u001b[0;34mf\"column {key}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot set a DataFrame with multiple columns to the single column region"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data SF"
      ],
      "metadata": {
        "id": "wmIxJDSbImiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b43da45-d586-481d-a96a-c662f27c4e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self.predir Datasets/SF_crime/\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/STHSL/train.py\", line 51, in <module>\n",
            "    main()\n",
            "  File \"/content/STHSL/train.py\", line 11, in main\n",
            "    engine = trainer(device)\n",
            "  File \"/content/STHSL/engine.py\", line 12, in __init__\n",
            "    self.handler = DataHandler()\n",
            "  File \"/content/STHSL/DataHandler.py\", line 23, in __init__\n",
            "    args.row, args.col, _, args.offNum = trnT.shape\n",
            "ValueError: not enough values to unpack (expected 4, got 2)\n"
          ]
        }
      ]
    }
  ]
}
